{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MaryGlad/Text-Generator/blob/main/Text_Generation_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BcYp2WnlpFCi"
      },
      "source": [
        "# libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 426
        },
        "id": "o30B69TC6vJa",
        "outputId": "c61169f7-ece8-4602-a6a6-ef45505b7943"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting anvil-uplink\n",
            "  Downloading anvil_uplink-0.4.2-py2.py3-none-any.whl (90 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.1/90.1 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting argparse (from anvil-uplink)\n",
            "  Downloading argparse-1.4.0-py2.py3-none-any.whl (23 kB)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.10/dist-packages (from anvil-uplink) (0.18.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from anvil-uplink) (1.16.0)\n",
            "Collecting ws4py (from anvil-uplink)\n",
            "  Downloading ws4py-0.5.1.tar.gz (51 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.4/51.4 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: ws4py\n",
            "  Building wheel for ws4py (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ws4py: filename=ws4py-0.5.1-py3-none-any.whl size=45228 sha256=d6b4d72e1d4eba38a2323213e3e2c15cef00bef43ba86101ee89fcc396615cf8\n",
            "  Stored in directory: /root/.cache/pip/wheels/2e/7c/ad/d9c746276bf024d44296340869fcb169f1e5d80fb147351a57\n",
            "Successfully built ws4py\n",
            "Installing collected packages: ws4py, argparse, anvil-uplink\n",
            "Successfully installed anvil-uplink-0.4.2 argparse-1.4.0 ws4py-0.5.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "argparse",
                  "google"
                ]
              }
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "!pip install anvil-uplink"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "oGPVvYf4STTi"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "import numpy as np\n",
        "import os\n",
        "import time\n",
        "import pathlib\n",
        "import anvil.server"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jMjuvLnSpKZz"
      },
      "source": [
        "# Making text generator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QIed46q0invG",
        "outputId": "2a8ea1de-ad0f-482e-f1cb-4a0096e3353a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SlYt_mPukaAb"
      },
      "outputs": [],
      "source": [
        "data = pathlib.Path('/content/drive/MyDrive/stories.txt') "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BfDP31-KSh8A"
      },
      "outputs": [],
      "source": [
        "text = open(data, 'rb').read().decode(encoding='utf-8')\n",
        "vocab = sorted(set(text))\n",
        "ids_chars = tf.keras.layers.StringLookup(\n",
        "    vocabulary=list(vocab), mask_token=None)\n",
        "chars_ids = tf.keras.layers.StringLookup(\n",
        "    vocabulary=ids_chars.get_vocabulary(), invert=True, mask_token=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ldyl58ikTRp4"
      },
      "outputs": [],
      "source": [
        "def text_from_ids(ids):\n",
        "  return tf.strings.reduce_join(chars_ids(ids), axis=-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y2DMlAb8TVea"
      },
      "outputs": [],
      "source": [
        "all_ids = ids_chars(tf.strings.unicode_split(text, 'UTF-8'))\n",
        "ids_dataset = tf.data.Dataset.from_tensor_slices(all_ids)\n",
        "sequences = ids_dataset.batch(101, drop_remainder=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qQ-xq10QT69E"
      },
      "outputs": [],
      "source": [
        "def splt_in_data(sequence):\n",
        "    input_text = sequence[:-1]\n",
        "    target_text = sequence[1:]\n",
        "    return input_text, target_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BqLMXxhPUCA4"
      },
      "outputs": [],
      "source": [
        "dataset = sequences.map(splt_in_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zc6b3xuiUHMY",
        "outputId": "6d259227-3bde-4daf-e8a6-796dc3712690"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<_PrefetchDataset element_spec=(TensorSpec(shape=(64, 100), dtype=tf.int64, name=None), TensorSpec(shape=(64, 100), dtype=tf.int64, name=None))>"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "BATCH_SIZE = 64\n",
        "\n",
        "BUFFER_SIZE = 10000\n",
        "\n",
        "dataset = (\n",
        "    dataset\n",
        "    .shuffle(BUFFER_SIZE)\n",
        "    .batch(BATCH_SIZE, drop_remainder=True)\n",
        "    .prefetch(tf.data.experimental.AUTOTUNE))\n",
        "\n",
        "dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CZpyegTKUO7s"
      },
      "outputs": [],
      "source": [
        "\n",
        "vocab_s = len(ids_chars.get_vocabulary())\n",
        "\n",
        "embed_dim = 256\n",
        "\n",
        "rnn_un = 1024"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j3J8ASmmUTZn"
      },
      "outputs": [],
      "source": [
        "class TextGenModel(tf.keras.Model):\n",
        "  def __init__(self, vocab_s, embed_dim, rnn_un):\n",
        "    super().__init__(self)\n",
        "    \n",
        "    self.embed = tf.keras.layers.Embedding(vocab_s, embed_dim)\n",
        "    self.gru = tf.keras.layers.GRU(rnn_un,\n",
        "                                   return_sequences=True,\n",
        "                                   return_state=True)\n",
        "    self.dense = tf.keras.layers.Dense(vocab_s)\n",
        "\n",
        "  def call(self, inputs, states=None, return_state=False, train=False):\n",
        "    x = inputs\n",
        "    x = self.embed(x, training=train)\n",
        "    if states is None:\n",
        "      states = self.gru.get_initial_state(x)\n",
        "    x, states = self.gru(x, initial_state=states, training=train)\n",
        "    x = self.dense(x, training=train)\n",
        "\n",
        "    if return_state:\n",
        "      return x, states\n",
        "    else:\n",
        "      return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fC7aZ6WEUaAQ"
      },
      "outputs": [],
      "source": [
        "model = TextGenModel(\n",
        "    vocab_s=vocab_s,\n",
        "    embed_dim=embed_dim,\n",
        "    rnn_un=rnn_un)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DNCYg3l_Ul2U"
      },
      "outputs": [],
      "source": [
        "loss = tf.losses.SparseCategoricalCrossentropy(from_logits=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5-6qToDHU_nh"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer='adam', loss=loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XHdMZC_5VCxo"
      },
      "outputs": [],
      "source": [
        "checkp_dir = './training_checkpoints'\n",
        "checkp_pref = os.path.join(checkp_dir, \"ckpt_{epoch}\")\n",
        "checkp_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkp_pref,\n",
        "    save_weights_only=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JNENWBDdVFNi"
      },
      "outputs": [],
      "source": [
        "EPOCHS = 200"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "NW-VtCsYVHnx",
        "outputId": "a2970640-8d45-40ad-9788-60f3789ae23e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "11/11 [==============================] - 88s 7s/step - loss: 4.5936\n",
            "Epoch 2/200\n",
            "11/11 [==============================] - 66s 6s/step - loss: 3.5689\n",
            "Epoch 3/200\n",
            "11/11 [==============================] - 65s 6s/step - loss: 3.1170\n",
            "Epoch 4/200\n",
            "11/11 [==============================] - 65s 6s/step - loss: 2.9594\n",
            "Epoch 5/200\n",
            "11/11 [==============================] - 64s 6s/step - loss: 2.7808\n",
            "Epoch 6/200\n",
            "11/11 [==============================] - 65s 6s/step - loss: 2.6120\n",
            "Epoch 7/200\n",
            "11/11 [==============================] - 64s 6s/step - loss: 2.4992\n",
            "Epoch 8/200\n",
            "11/11 [==============================] - 64s 6s/step - loss: 2.4165\n",
            "Epoch 9/200\n",
            "11/11 [==============================] - 64s 6s/step - loss: 2.3544\n",
            "Epoch 10/200\n",
            "11/11 [==============================] - 64s 6s/step - loss: 2.3038\n",
            "Epoch 11/200\n",
            "11/11 [==============================] - 64s 6s/step - loss: 2.2621\n",
            "Epoch 12/200\n",
            "11/11 [==============================] - 64s 6s/step - loss: 2.2319\n",
            "Epoch 13/200\n",
            "11/11 [==============================] - 63s 6s/step - loss: 2.1988\n",
            "Epoch 14/200\n",
            "11/11 [==============================] - 64s 6s/step - loss: 2.1709\n",
            "Epoch 15/200\n",
            "11/11 [==============================] - 66s 6s/step - loss: 2.1437\n",
            "Epoch 16/200\n",
            "11/11 [==============================] - 65s 6s/step - loss: 2.1165\n",
            "Epoch 17/200\n",
            "11/11 [==============================] - 65s 6s/step - loss: 2.0879\n",
            "Epoch 18/200\n",
            "11/11 [==============================] - 65s 6s/step - loss: 2.0604\n",
            "Epoch 19/200\n",
            "11/11 [==============================] - 64s 6s/step - loss: 2.0331\n",
            "Epoch 20/200\n",
            "11/11 [==============================] - 65s 6s/step - loss: 2.0015\n",
            "Epoch 21/200\n",
            "11/11 [==============================] - 64s 6s/step - loss: 1.9734\n",
            "Epoch 22/200\n",
            "11/11 [==============================] - 65s 6s/step - loss: 1.9430\n",
            "Epoch 23/200\n",
            "11/11 [==============================] - 66s 6s/step - loss: 1.9166\n",
            "Epoch 24/200\n",
            "11/11 [==============================] - 66s 6s/step - loss: 1.8863\n",
            "Epoch 25/200\n",
            "11/11 [==============================] - 65s 6s/step - loss: 1.8571\n",
            "Epoch 26/200\n",
            "11/11 [==============================] - 64s 6s/step - loss: 1.8283\n",
            "Epoch 27/200\n",
            "11/11 [==============================] - 64s 6s/step - loss: 1.8011\n",
            "Epoch 28/200\n",
            "11/11 [==============================] - 65s 6s/step - loss: 1.7678\n",
            "Epoch 29/200\n",
            "11/11 [==============================] - 65s 6s/step - loss: 1.7395\n",
            "Epoch 30/200\n",
            "11/11 [==============================] - 65s 6s/step - loss: 1.7089\n",
            "Epoch 31/200\n",
            "11/11 [==============================] - 64s 6s/step - loss: 1.6776\n",
            "Epoch 32/200\n",
            "11/11 [==============================] - 65s 6s/step - loss: 1.6477\n",
            "Epoch 33/200\n",
            "11/11 [==============================] - 65s 6s/step - loss: 1.6145\n",
            "Epoch 34/200\n",
            "11/11 [==============================] - 65s 6s/step - loss: 1.5804\n",
            "Epoch 35/200\n",
            "11/11 [==============================] - 68s 6s/step - loss: 1.5506\n",
            "Epoch 36/200\n",
            "11/11 [==============================] - 65s 6s/step - loss: 1.5142\n",
            "Epoch 37/200\n",
            "11/11 [==============================] - 64s 6s/step - loss: 1.4761\n",
            "Epoch 38/200\n",
            "11/11 [==============================] - 65s 6s/step - loss: 1.4382\n",
            "Epoch 39/200\n",
            "11/11 [==============================] - 65s 6s/step - loss: 1.4000\n",
            "Epoch 40/200\n",
            "11/11 [==============================] - 65s 6s/step - loss: 1.3587\n",
            "Epoch 41/200\n",
            "11/11 [==============================] - 65s 6s/step - loss: 1.3174\n",
            "Epoch 42/200\n",
            "11/11 [==============================] - 64s 6s/step - loss: 1.2715\n",
            "Epoch 43/200\n",
            "11/11 [==============================] - 65s 6s/step - loss: 1.2260\n",
            "Epoch 44/200\n",
            "11/11 [==============================] - 65s 6s/step - loss: 1.1794\n",
            "Epoch 45/200\n",
            "11/11 [==============================] - 70s 6s/step - loss: 1.1339\n",
            "Epoch 46/200\n",
            "11/11 [==============================] - 65s 6s/step - loss: 1.0848\n",
            "Epoch 47/200\n",
            "11/11 [==============================] - 65s 6s/step - loss: 1.0312\n",
            "Epoch 48/200\n",
            "11/11 [==============================] - 65s 6s/step - loss: 0.9745\n",
            "Epoch 49/200\n",
            "11/11 [==============================] - 65s 6s/step - loss: 0.9187\n",
            "Epoch 50/200\n",
            " 1/11 [=>............................] - ETA: 1:02 - loss: 0.8408"
          ]
        }
      ],
      "source": [
        "history = model.fit(dataset, epochs=EPOCHS, callbacks=[checkp_callback])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GUuCi_eIhtFx"
      },
      "outputs": [],
      "source": [
        "class Generating(tf.keras.Model):\n",
        "  def __init__(self, model, chars_ids, ids_chars, temperature=0.5):\n",
        "    super().__init__()\n",
        "\n",
        "    self.temperature = temperature\n",
        "    self.model = model\n",
        "    self.chars_ids = chars_ids\n",
        "    self.ids_chars = ids_chars\n",
        "\n",
        "    skip_ids = self.ids_chars(['[UNK]'])[:, None]\n",
        "    sparse_mask = tf.SparseTensor(\n",
        "        values=[-float('inf')]*len(skip_ids),\n",
        "        indices=skip_ids,\n",
        "        dense_shape=[len(ids_chars.get_vocabulary())])\n",
        "    self.pred_mask = tf.sparse.to_dense(sparse_mask)\n",
        "\n",
        "  @tf.function\n",
        "  def gen_one_step(self, inputs, states=None):\n",
        "    input_chars = tf.strings.unicode_split(inputs, 'UTF-8')\n",
        "    input_ids = self.ids_chars(input_chars).to_tensor()\n",
        "\n",
        "    pred_logits, states = self.model(inputs=input_ids, states=states,\n",
        "                                          return_state=True)\n",
        "    pred_logits = pred_logits[:, -1, :]\n",
        "    pred_logits = pred_logits/self.temperature\n",
        "    pred_logits = pred_logits + self.pred_mask\n",
        "\n",
        "    pred_ids = tf.random.categorical(pred_logits, num_samples=1)\n",
        "    pred_ids = tf.squeeze(pred_ids, axis=-1)\n",
        "\n",
        "    pred_chars = self.chars_ids(pred_ids)\n",
        "\n",
        "    return pred_chars, states"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ad74tDZpht_1"
      },
      "outputs": [],
      "source": [
        "gen_text = Generating(model, chars_ids, ids_chars)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HXj9RRZK68Xt"
      },
      "source": [
        "# WEB"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xcsf_NJV6_d4"
      },
      "outputs": [],
      "source": [
        "anvil.server.connect(\"server_FHBYG73CHW6LP5P3525ZB2UM-CVWDV7XBAJZLGH4P\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TbyJFUBT7jNR"
      },
      "outputs": [],
      "source": [
        "@anvil.server.callable\n",
        "def generate_text(i):\n",
        "  nxt_char = tf.constant([i])\n",
        "  result = [nxt_char]\n",
        "  n_char = 200\n",
        "  states = None\n",
        "  for n in range(n_char):\n",
        "    nxt_char, states = gen_text.gen_one_step(nxt_char, states=states)\n",
        "    result.append(nxt_char)\n",
        "  result = tf.strings.join(result)\n",
        "  return result[0].numpy().decode('utf-8')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "crbLLG7MCRSz"
      },
      "outputs": [],
      "source": [
        "anvil.server.wait_forever()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}